{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71234c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "#Как работает данная модель сверточной нейронной сети: \n",
    "#    1. По адресу: https://drive.google.com/drive/folders/1x5-92pU8kzd-UngaddUCR7WJtDrbAG1N?usp=drive_link - расположены .wav-файлы со звуком плохой фистулы  (для работы модели сохраняла файлы локально в папку \"../fistulas_sound/bad\", всего 6 аудио-файлов)\n",
    "#    2. По адресу: https://drive.google.com/drive/folders/1EmN3jzet_dXdnmFG8wu0KpShHi84tKMM?usp=drive_link - расположены .wav-файлы со звуком хорошей фистулы (для работы модели сохраняла файлы локально в папку \"../fistulas_sound/good\", всего 4 аудио-файла)\n",
    "#    3. По адресу: https://drive.google.com/file/d/1mk6ppeIqiBpDIMBebteRo8jqQDU0WB9I/view?usp=drive_link - расположены заархивированные .wav-файлы, подлежащие классификации (для работы модели сохраняла файлы локально в папку \"../fistulas_sound/vita-fs-data\", всего 875 аудио-файлов)\n",
    "#    4. С помощью библиотеки librosa тренировочные аудио-файлы (п.1-2) из формата .wav перегоняются в формат .png (спектрограммы) и сохраняются в папки \"../img_data/good\" (4 спектрограммы) и \"../img_data/bad\" (6 спектрограмм) соответственно.\n",
    "#    5. Разбиваем исходный, классифицированный ранее, набор данных (п.1-2) на обучающую и тестовую выборки в соотношении 80/20: для этого сохраняем в папки \"../data/train/bad\" (четыре \"плохих\" спектрограммы из шести) и \"../data/train/good\" (три \"хороших\" спектрограммы из четырёх) 80% исходного набора тренировочных данных, а в папки \"../data/val/bad\" (две оставшиеся \"плохих\" спектрограммы из шести) и \"../data/val/good\" (одна оставшаяся \"хорошая\" спектрограмма из четырёх) - 20% исходного набора тренировочных данных.\n",
    "#    6. Используя класс Sequential() из keras формируем модель свёрточной нейронной сети (convolutional neural network (CNN)).\n",
    "#    7. Обучаем модель с помощью стохастического градиентного спуска (SGD).\n",
    "#    8. Производим оценку модели, результаты такие: потери - 0,66%, точность - 67%. Для большей точности нужно оптимизировать модель (поле для разработки!).\n",
    "#    9. Выгружаем модель свёрточной нейронной сети в формат .pickle, подходящий для загрузки в ИС \"Vita-Control\", позволяющей выполнять бинарную классификацию данных через пользовательский интерфейс (загрузка в БД ИС - отдельная задача). \n",
    "#    10. Переносим максимальное кол-во файлов, кратное размеру пачки (в данном случае - 32) в формат .png действиями, аналогичными действиям из п.4. Из доступных 875 файлов классификации будет подвержено 864 файла (875 - (875 mod 32) = 864). Спектрограммы сохраняем в папку \"../data/test/unclassified\".   \n",
    "#    11. Выполняем прогноз на основном тестовом наборе данных (864 спектрограммы звука из папки \"../data/test/unclassified\").\n",
    "#    12. Сопоставляем результаты классификации (результаты не нравятся - здесь проверить код! попозже посмотрю)\n",
    "#    13. Записываем результат бинарной классификации в файл \"prediction_results_CNN_model.csv\".\n",
    "#P.S. Источник - https://nuancesprog.ru/p/6758/ - всё очень понятно написано. \n",
    "#############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e67f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#п.1-3 делаем до запуска IDE (формировала модель в локальном jupyter-notebook.\n",
    "#Далее в листинге в комментах будет указан номер пункта из описанной выше работы модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c108ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#импортируем нужные библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "import random\n",
    "import warnings\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f034b455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Chernyavskaya_OS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#подключаем tensorflow, keras - в его составе\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9dc739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#подключаем элементы keras\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD #градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50996cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#п.4 описания - формируем директорию img_data, содержащую все изображения, классифицированные по видам фистул: плохая/хорошая\n",
    "fistulas_kind = 'good bad'.split()\n",
    "for f in fistulas_kind:\n",
    "    pathlib.Path(f'img_data/{f}').mkdir(parents=True, exist_ok=True)\n",
    "    for filename in os.listdir(f'fistulas_sound/{f}/'):\n",
    "        wav_name = f'fistulas_sound/{f}/{filename}'\n",
    "        y, sr = librosa.load(wav_name, mono=True, duration=5)\n",
    "        #print(y.shape)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap='Blues', sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'img_data/{f}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b3aad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 10 files [00:00, 76.46 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "#п.5 описания - разбиваем на обучающую и тестовую выборки: 80/20\n",
    "splitfolders.ratio('./img_data/', output=\"./data\", seed=1337, ratio=(.8, .2)) # значения по умолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9777ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, #изменение масштаба всех значений пикселей с 0 до 255, после этого шага они будут находится в диапазоне (0..1)\n",
    "        shear_range=0.2, #применение случайных преобразований\n",
    "        zoom_range=0.2, #увеличение масштаба\n",
    "        horizontal_flip=True) #горизонтальный поворот\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c50c378f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 images belonging to 2 classes.\n",
      "Found 3 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "        './data/train',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle = False)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        './data/val',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81ed127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Chernyavskaya_OS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 31, 31, 32)        896       \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 15, 15, 32)        0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 7, 7, 64)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " average_pooling2d_2 (Avera  (None, 3, 3, 64)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 3, 3, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93378 (364.76 KB)\n",
      "Trainable params: 93378 (364.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#п.6 описания - формируем модель свёрточной нейронной сети:\n",
    "model_CNN = Sequential()\n",
    "input_shape=(64, 64, 3)\n",
    "\n",
    "#первый скрытый слой\n",
    "model_CNN.add(Conv2D(32, (3, 3), strides=(2, 2), input_shape=input_shape))\n",
    "model_CNN.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model_CNN.add(Activation('relu'))\n",
    "\n",
    "#второй скрытый слой\n",
    "model_CNN.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model_CNN.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model_CNN.add(Activation('relu'))\n",
    "\n",
    "#третий скрытый слой\n",
    "model_CNN.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model_CNN.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model_CNN.add(Activation('relu'))\n",
    "\n",
    "#слой выравнивания\n",
    "model_CNN.add(Flatten())\n",
    "model_CNN.add(Dropout(rate=0.5))\n",
    "\n",
    "#полносвязный слой\n",
    "model_CNN.add(Dense(64))\n",
    "model_CNN.add(Activation('relu'))\n",
    "model_CNN.add(Dropout(rate=0.5))\n",
    "\n",
    "#выходной слой\n",
    "model_CNN.add(Dense(2))\n",
    "model_CNN.add(Activation('softmax'))\n",
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3e7f529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Chernyavskaya_OS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#п.7 описания - обучаем модель - команда compile\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "learning_rate = 0.01\n",
    "decay_rate = learning_rate/epochs\n",
    "momentum = 0.9\n",
    "sgd = SGD(learning_rate=learning_rate, momentum=momentum, weight_decay=decay_rate, nesterov=False) #sgd - это стох.град.спуск\n",
    "model_CNN.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=['accuracy']) #кросс-энтропию - проверить, возможно, заменить параметры модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9559725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Chernyavskaya_OS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Chernyavskaya_OS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7895 - accuracy: 0.4286 - val_loss: 0.6728 - val_accuracy: 0.6667\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6771 - accuracy: 0.7143 - val_loss: 0.6774 - val_accuracy: 0.6667\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.7497 - accuracy: 0.4286 - val_loss: 0.6827 - val_accuracy: 0.6667\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7010 - accuracy: 0.4286 - val_loss: 0.6882 - val_accuracy: 0.6667\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.6715 - accuracy: 0.5714 - val_loss: 0.6807 - val_accuracy: 0.6667\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7719 - accuracy: 0.4286 - val_loss: 0.6821 - val_accuracy: 0.6667\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6960 - accuracy: 0.4286 - val_loss: 0.6724 - val_accuracy: 0.6667\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6831 - accuracy: 0.5714 - val_loss: 0.6701 - val_accuracy: 0.6667\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6298 - accuracy: 0.7143 - val_loss: 0.6680 - val_accuracy: 0.6667\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6726 - accuracy: 0.7143 - val_loss: 0.6697 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f077a65310>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CNN.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=1,\n",
    "        epochs=10,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a272cd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6696901321411133, 0.6666666865348816]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#п.8 описания - оценка модели\n",
    "model_CNN.evaluate_generator(generator=test_set, steps=1) #потери - 0,66%, точность - 67%, мало :P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9cf60b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#п.9 описания - выгружаем модель свёрточной нейронной сети в формат .pickle для загрузки в ИС \"Vita-Control\", позволяющей выполнять классификацию данных через GUI (Web). \n",
    "import pickle\n",
    "data = model_CNN\n",
    "with open('model_CNN.pickle', 'wb') as f:\n",
    "  pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c238973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(0,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(5645,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(5645,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "cp.sh\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(39514,)\n",
      "(62093,)\n",
      "(50804,)\n",
      "(39514,)\n",
      "(45159,)\n",
      "(28224,)\n",
      "(33869,)\n",
      "(28224,)\n",
      "(39514,)\n",
      "(28224,)\n",
      "(62093,)\n",
      "(28224,)\n",
      "(50804,)\n",
      "(39514,)\n",
      "(39514,)\n",
      "(16935,)\n",
      "(28224,)\n",
      "(67738,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n",
      "(110250,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#п.10 описания - переносим основные данные wav->png для классификации с пом.построенной модели (переношу только 864 файла из 875, т.к. размер пачки установила (ниже) = 32),\n",
    "#для вывода рез-тов классиф-ии в файл нужно, чтобы совпадало кол-во сэмплов и рез-тов (это 2 столбца в результирующем .csv)\n",
    "li_cnt = 0 #счётчик перенесенных файлов\n",
    "pathlib.Path(f'data/test/unclassified').mkdir(parents=True, exist_ok=True)\n",
    "for filename in os.listdir(f'fistulas_sound/vita-fs-data/'):\n",
    "    if li_cnt < 864:\n",
    "        try:\n",
    "            wav_name = f'fistulas_sound/vita-fs-data/{filename}'\n",
    "            y, sr = librosa.load(wav_name, mono=True, duration=5)\n",
    "            print(y.shape)\n",
    "            plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap='Blues', sides='default', mode='default', scale='dB');\n",
    "            plt.axis('off');\n",
    "            plt.savefig(f'data/test/unclassified/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "            plt.clf()\n",
    "            li_cnt = li_cnt + 1\n",
    "        except:\n",
    "            print(filename)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "393c6c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 864 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "main_test_set = test_datagen.flow_from_directory(\n",
    "        './data/test',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9b624fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 33s 1s/step\n"
     ]
    }
   ],
   "source": [
    "#п.11 описания - выполняем прогноз на основном тестовом наборе данных (864 спектрограммы звука).\n",
    "main_test_set.reset()\n",
    "pred = model_CNN.predict_generator(main_test_set, steps=27, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16d66b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#п.12 описания - сопоставляем рез-ты классификации\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "labels = (training_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "predictions = predictions[:864]\n",
    "filenames=main_test_set.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a4a3755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864 864\n"
     ]
    }
   ],
   "source": [
    "#защита от дурака - кол-во классифицируемых записей д.б. = кол-ву выполненных прогнозов.\n",
    "print(len(filenames), len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e93d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#п.13 описания - записываем рез-т в файл \"prediction_results_CNN_model.csv\"\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"prediction_results_CNN_model.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea41d5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
